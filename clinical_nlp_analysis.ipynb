{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Standardized EDA: Clinical NLP Analysis\n",
                "\n",
                "This notebook performs a comprehensive **Exploratory Data Analysis (EDA)** on the Clinical Notes Dataset.\n",
                "**Goal**: Analyze unstructured text properties to inform NLP model selection.\n",
                "\n",
                "## Objectives\n",
                "1. **Inspection**: Load text data and review structure.\n",
                "2. **Cleaning**: Normalize text and handle nulls.\n",
                "3. **Analysis**: Distribution of note lengths and entity frequencies.\n",
                "4. **Modeling**: Abstractive summarization demo.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies if missing\n",
                "!pip install datasets transformers\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from datasets import load_dataset\n",
                "from transformers import pipeline\n",
                "\n",
                "# Visualization Settings\n",
                "sns.set_style(\"whitegrid\")\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "\n",
                "def add_annotations(ax):\n",
                "    \"\"\"Add value labels to bars/points.\"\"\"\n",
                "    for p in ax.patches:\n",
                "        if p.get_height() > 0:\n",
                "            ax.annotate(f'{int(p.get_height())}', \n",
                "                        (p.get_x() + p.get_width() / 2., p.get_height()), \n",
                "                        ha='center', va='center', \n",
                "                        fontsize=10, color='black', xytext=(0, 5), \n",
                "                        textcoords='offset points')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading & Inspection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Loading dataset...\")\n",
                "try:\n",
                "    # Using Hugging Face dataset as primary source\n",
                "    dataset = load_dataset(\"AGBonnet/augmented-clinical-notes\", split=\"train\", streaming=True)\n",
                "    data_head = list(dataset.take(200)) # Take 200 samples for EDA\n",
                "    df = pd.DataFrame(data_head)\n",
                "    print(f\"Loaded {len(df)} records.\")\n",
                "    print(\"Columns:\", df.columns.tolist())\n",
                "    display(df.head(2))\n",
                "except Exception as e:\n",
                "    print(f\"Error loading dataset: {e}\")\n",
                "    # Fallback Mock Data\n",
                "    df = pd.DataFrame({'note': ['Patient presented with...', 'Follow up visit...', 'Emergency admission...']*30})\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Column Renaming & Cleaning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not df.empty:\n",
                "    # 2.1 Snake Case\n",
                "    df.columns = [c.lower().replace(' ', '_') for c in df.columns]\n",
                "    print(\"Renamed Columns:\", df.columns.tolist())\n",
                "    \n",
                "    # 2.2 Identify Text Column\n",
                "    # Heuristic: look for 'note', 'text', 'transcription'\n",
                "    text_col = next((c for c in df.columns if c in ['note', 'transcription', 'text']), None)\n",
                "    if not text_col:\n",
                "        text_col = df.columns[0]\n",
                "    print(f\"Target Text Column: '{text_col}'\")\n",
                "\n",
                "    # 2.3 Handle Missing\n",
                "    df = df.dropna(subset=[text_col])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Feature Engineering (Text Properties)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate basic text metrics\n",
                "df['char_count'] = df[text_col].astype(str).apply(len)\n",
                "df['word_count'] = df[text_col].astype(str).apply(lambda x: len(x.split()))\n",
                "df['sentence_count'] = df[text_col].astype(str).apply(lambda x: x.count('.') + x.count('!'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Univariate Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4.1 Word Count Distribution\n",
                "plt.figure(figsize=(10, 5))\n",
                "sns.histplot(df['word_count'], bins=30, kde=True, color='purple')\n",
                "plt.title('Distribution of Note Length (Words)')\n",
                "plt.xlabel('Word Count')\n",
                "plt.show()\n",
                "\n",
                "# 4.2 Boxplot for Outliers\n",
                "plt.figure(figsize=(10, 2))\n",
                "sns.boxplot(x=df['word_count'], color='lavender')\n",
                "plt.title('Word Count Boxplot')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. NLP Modeling: Abstractive Summarization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Model\n",
                "try:\n",
                "    summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
                "    \n",
                "    # Summarize Sample\n",
                "    sample_text = df[text_col].iloc[0]\n",
                "    if len(sample_text.split()) > 200: # Truncate for demo speed\n",
                "        sample_text = \" \".join(sample_text.split()[:200])\n",
                "        \n",
                "    summary = summarizer(sample_text, max_length=60, min_length=10, do_sample=False)\n",
                "    \n",
                "    print(\"--- ORIGINAL ---\")\n",
                "    print(sample_text)\n",
                "    print(\"\\n--- SUMMARY ---\")\n",
                "    print(summary[0]['summary_text'])\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f\"Summarization skipped: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Insights\n",
                "\n",
                "*   **Length**: Most notes are varying in length, indicating verbose documentation.\n",
                "*   **Processing**: Long-context models (like Longformer) might be needed for full note coverage.\n",
                "*   **Compression**: Summarization effectively condenses the content."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
